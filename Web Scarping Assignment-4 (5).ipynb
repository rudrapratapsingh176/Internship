{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecfd47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82610737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import SessionNotCreatedException\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "881a9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "page13=requests.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "soup13=BeautifulSoup(page13.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d79ca6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a926e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in soup13.find_all('tr')[2:32]:\n",
    "    Rank.append(i.text.split('\\n')[1])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa6b2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup13.find_all('tr')[2:32]:\n",
    "    Name.append(i.text.split('\\n')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4097951",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup13.find_all('tr')[2:32]:\n",
    "    Artist.append(i.text.split('\\n')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e446ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup13.find_all('tr')[2:32]:\n",
    "    Upload_date.append(i.text.split('\\n')[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "544d216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup13.find_all('tr')[2:32]:\n",
    "    Views.append(i.text.split('\\n')[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca8ac71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>12.27</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.08</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.61</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>6.01</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.91</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.78</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.15</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[24]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.92</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[25]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.83</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.81</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.69</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.53</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.23</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.82</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Axel F\"[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.75</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[36]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.73</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[37]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.72</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.63</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.55</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.49</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[41]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.47</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.45</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.40</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.38</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"[45]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.37</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.37</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.33</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.33</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.30</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[50]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.30</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                          \"Wheels on the Bus\"[24]   \n",
       "8    9.                                \"Uptown Funk\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                     \"Axel F\"[35]   \n",
       "15  16.                                       \"Roar\"[36]   \n",
       "16  17.                             \"Counting Stars\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
       "21  22.                                 \"Dark Horse\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.                             \"Girls Like You\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                             \"Lakdi Ki Kathi\"[50]   \n",
       "\n",
       "                                           Artist Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories       12.27   \n",
       "1                                      Luis Fonsi        8.08   \n",
       "2                                     LooLoo Kids        6.61   \n",
       "3                      Cocomelon – Nursery Rhymes        6.01   \n",
       "4                                      Ed Sheeran        5.91   \n",
       "5                                     Wiz Khalifa        5.78   \n",
       "6                                       ChuChu TV        5.15   \n",
       "7                      Cocomelon – Nursery Rhymes        4.92   \n",
       "8                                     Mark Ronson        4.83   \n",
       "9                                     Miroshka TV        4.81   \n",
       "10                                            Psy        4.69   \n",
       "11                                     Get Movies        4.53   \n",
       "12                                      El Chombo        4.23   \n",
       "13                                       Maroon 5        3.82   \n",
       "14                                     Crazy Frog        3.75   \n",
       "15                                     Katy Perry        3.73   \n",
       "16                                    OneRepublic        3.72   \n",
       "17                                  Justin Bieber        3.63   \n",
       "18                                     Ed Sheeran        3.55   \n",
       "19                     Cocomelon – Nursery Rhymes        3.49   \n",
       "20                                        Shakira        3.47   \n",
       "21                                     Katy Perry        3.45   \n",
       "22                                    Alan Walker        3.40   \n",
       "23                                      Passenger        3.38   \n",
       "24                                       Maroon 5        3.37   \n",
       "25                                     Ed Sheeran        3.37   \n",
       "26                               Enrique Iglesias        3.33   \n",
       "27                                    Major Lazer        3.33   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs        3.30   \n",
       "29                                   Jingle Toons        3.30   \n",
       "\n",
       "                Views  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6       March 6, 2014  \n",
       "7        May 24, 2018  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13   January 14, 2015  \n",
       "14      June 16, 2009  \n",
       "15  September 5, 2013  \n",
       "16       May 31, 2013  \n",
       "17   October 22, 2015  \n",
       "18    October 7, 2014  \n",
       "19      June 25, 2018  \n",
       "20       June 4, 2010  \n",
       "21  February 20, 2014  \n",
       "22   December 3, 2015  \n",
       "23      July 25, 2012  \n",
       "24       May 31, 2018  \n",
       "25   November 9, 2017  \n",
       "26     April 11, 2014  \n",
       "27     March 22, 2015  \n",
       "28   January 26, 2018  \n",
       "29      June 14, 2018  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'Name':Name,'Artist':Artist,'Upload Date':Upload_date,'Views':Views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02d0f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\rudra\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3ef8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "735054d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div/div[1]')\n",
    "team.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79499254",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div/div[2]/div[1]/input')\n",
    "search.send_keys('India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abc16bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Team=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div[2]/div/button')\n",
    "Team.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e41a11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d681a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st Test - Vidarbha Cricket Association Stadium',\n",
       " '1st T20I - Newlands',\n",
       " '2nd T20I - Newlands',\n",
       " '2nd Test - Arun Jaitley Stadium',\n",
       " \"3rd T20I - St George's Park\",\n",
       " \"4th T20I - St George's Park\",\n",
       " '3rd Test - Himachal Pradesh Cricket Association Stadium',\n",
       " '4th Test - Narendra Modi Stadium']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text.split(',')[0]\n",
    "    Match_title.append(brand1)\n",
    "Match_title    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ef94c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23',\n",
       " 'ICC WOMENS T20 WORLD CUP 2023',\n",
       " 'ICC WOMENS T20 WORLD CUP 2023',\n",
       " 'AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23',\n",
       " 'ICC WOMENS T20 WORLD CUP 2023',\n",
       " 'ICC WOMENS T20 WORLD CUP 2023',\n",
       " 'AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23',\n",
       " 'AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Series.append(brand1)\n",
    "Series    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88059708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Nagpur',\n",
       " ' Cape Town',\n",
       " ' Cape Town',\n",
       " ' Delhi',\n",
       " ' Gqeberha',\n",
       " ' Gqeberha',\n",
       " ' Dharamsala',\n",
       " ' Ahmedabad']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text.split(',')[1]\n",
    "    Place.append(brand1)\n",
    "Place    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2ba0a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9 FEB 2023',\n",
       " '12 FEB 2023',\n",
       " '15 FEB 2023',\n",
       " '17 FEB 2023',\n",
       " '18 FEB 2023',\n",
       " '20 FEB 2023',\n",
       " '1 MAR 2023',\n",
       " '9 MAR 2023']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//div[@class=\"match-card-left match-schedule\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Date.append(brand1)\n",
    "Date    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "463c9eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9:30 AM IST',\n",
       " '6:30 PM IST',\n",
       " '6:30 PM IST',\n",
       " '9:30 AM IST',\n",
       " '6:30 PM IST',\n",
       " '6:30 PM IST',\n",
       " '9:30 AM IST',\n",
       " '9:30 AM IST']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//div[@class=\"match-card-right match-schedule \"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Time.append(brand1)\n",
    "Time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2255fda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test - Vidarbha Cricket Association Stadium</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>9 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I - Newlands</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>12 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd T20I - Newlands</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>15 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd Test - Arun Jaitley Stadium</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>17 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd T20I - St George's Park</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Gqeberha</td>\n",
       "      <td>18 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4th T20I - St George's Park</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Gqeberha</td>\n",
       "      <td>20 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd Test - Himachal Pradesh Cricket Associatio...</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Dharamsala</td>\n",
       "      <td>1 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4th Test - Narendra Modi Stadium</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>9 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Match Title  \\\n",
       "0    1st Test - Vidarbha Cricket Association Stadium   \n",
       "1                                1st T20I - Newlands   \n",
       "2                                2nd T20I - Newlands   \n",
       "3                    2nd Test - Arun Jaitley Stadium   \n",
       "4                        3rd T20I - St George's Park   \n",
       "5                        4th T20I - St George's Park   \n",
       "6  3rd Test - Himachal Pradesh Cricket Associatio...   \n",
       "7                   4th Test - Narendra Modi Stadium   \n",
       "\n",
       "                                        Series        Place         Date  \\\n",
       "0  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23       Nagpur   9 FEB 2023   \n",
       "1                ICC WOMENS T20 WORLD CUP 2023    Cape Town  12 FEB 2023   \n",
       "2                ICC WOMENS T20 WORLD CUP 2023    Cape Town  15 FEB 2023   \n",
       "3  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23        Delhi  17 FEB 2023   \n",
       "4                ICC WOMENS T20 WORLD CUP 2023     Gqeberha  18 FEB 2023   \n",
       "5                ICC WOMENS T20 WORLD CUP 2023     Gqeberha  20 FEB 2023   \n",
       "6  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   Dharamsala   1 MAR 2023   \n",
       "7  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23    Ahmedabad   9 MAR 2023   \n",
       "\n",
       "          Time  \n",
       "0  9:30 AM IST  \n",
       "1  6:30 PM IST  \n",
       "2  6:30 PM IST  \n",
       "3  9:30 AM IST  \n",
       "4  6:30 PM IST  \n",
       "5  6:30 PM IST  \n",
       "6  9:30 AM IST  \n",
       "7  9:30 AM IST  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Match Title':Match_title,'Series':Series,'Place':Place,'Date':Date,'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8826275",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\rudra\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07d4c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "economey=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "economey.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5317bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "economey=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "economey.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99552f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "economey=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "economey.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a07263ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_18_19=[]\n",
    "GDSP_19_20=[]\n",
    "Share_18_19=[]\n",
    "GDP=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4a288a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"data1\"]')[0:33]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Rank.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "647b8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "State1=[]\n",
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"name\"]')[0:33]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    State1.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4fa8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]')[0:33]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    GSDP_18_19.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad21cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[0:165:5]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    GDSP_19_20.append(brand1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "861f9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[1:165:5]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Share_18_19.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5facaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[2:165:5]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    GDP.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "399f2938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 33, 33, 33, 33)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rank),len(State1),len(GSDP_18_19),len(GDSP_19_20),len(GDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63c7e716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19) GSDP(19-20) Share(18-19)  \\\n",
       "0     1                Maharashtra   2,632,792           -       13.94%   \n",
       "1     2                 Tamil Nadu   1,630,208   1,845,853        8.63%   \n",
       "2     3              Uttar Pradesh   1,584,764   1,687,818        8.39%   \n",
       "3     4                    Gujarat   1,502,899           -        7.96%   \n",
       "4     5                  Karnataka   1,493,127   1,631,977        7.91%   \n",
       "5     6                West Bengal   1,089,898   1,253,832        5.77%   \n",
       "6     7                  Rajasthan     942,586   1,020,989        4.99%   \n",
       "7     8             Andhra Pradesh     862,957     972,782        4.57%   \n",
       "8     9                  Telangana     861,031     969,604        4.56%   \n",
       "9    10             Madhya Pradesh     809,592     906,672        4.29%   \n",
       "10   11                     Kerala     781,653           -        4.14%   \n",
       "11   12                      Delhi     774,870     856,112        4.10%   \n",
       "12   13                    Haryana     734,163     831,610        3.89%   \n",
       "13   14                      Bihar     530,363     611,804        2.81%   \n",
       "14   15                     Punjab     526,376     574,760        2.79%   \n",
       "15   16                     Odisha     487,805     521,275        2.58%   \n",
       "16   17                      Assam     315,881           -        1.67%   \n",
       "17   18               Chhattisgarh     304,063     329,180        1.61%   \n",
       "18   19                  Jharkhand     297,204     328,598        1.57%   \n",
       "19   20                Uttarakhand     245,895           -        1.30%   \n",
       "20   21            Jammu & Kashmir     155,956           -        0.83%   \n",
       "21   22           Himachal Pradesh     153,845     165,472        0.81%   \n",
       "22   23                        Goa      73,170      80,449        0.39%   \n",
       "23   24                    Tripura      49,845      55,984        0.26%   \n",
       "24   25                 Chandigarh      42,114           -        0.22%   \n",
       "25   26                 Puducherry      34,433      38,253        0.18%   \n",
       "26   27                  Meghalaya      33,481      36,572        0.18%   \n",
       "27   28                     Sikkim      28,723      32,496        0.15%   \n",
       "28   29                    Manipur      27,870      31,790        0.15%   \n",
       "29   30                   Nagaland      27,283           -        0.14%   \n",
       "30   31          Arunachal Pradesh      24,603           -        0.13%   \n",
       "31   32                    Mizoram      22,287      26,503        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP($Billion)  \n",
       "0        399.921  \n",
       "1        247.629  \n",
       "2        240.726  \n",
       "3        228.290  \n",
       "4        226.806  \n",
       "5        165.556  \n",
       "6        143.179  \n",
       "7        131.083  \n",
       "8        130.791  \n",
       "9        122.977  \n",
       "10       118.733  \n",
       "11       117.703  \n",
       "12       111.519  \n",
       "13        80.562  \n",
       "14        79.957  \n",
       "15        74.098  \n",
       "16        47.982  \n",
       "17        46.187  \n",
       "18        45.145  \n",
       "19        37.351  \n",
       "20        23.690  \n",
       "21        23.369  \n",
       "22        11.115  \n",
       "23         7.571  \n",
       "24         6.397  \n",
       "25         5.230  \n",
       "26         5.086  \n",
       "27         4.363  \n",
       "28         4.233  \n",
       "29         4.144  \n",
       "30         3.737  \n",
       "31         3.385  \n",
       "32             -  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'State':State1,'GSDP(18-19)':GSDP_18_19,'GSDP(19-20)':GDSP_19_20,'Share(18-19)':Share_18_19,'GDP($Billion)':GDP})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b712e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\rudra\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97728599",
   "metadata": {},
   "outputs": [],
   "source": [
    "source=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aef6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9417f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1aa300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/acikkaynak/deprem-yardim-frontend',\n",
       " 'https://github.com/acikkaynak/deprem-yardim-backend',\n",
       " 'https://github.com/AutumnWhj/ChatGPT-wechat-bot',\n",
       " 'https://github.com/fuergaosi233/wechat-chatgpt',\n",
       " 'https://github.com/dabit3/gpt-travel-advisor',\n",
       " 'https://github.com/f/awesome-chatgpt-prompts',\n",
       " 'https://github.com/motion-canvas/motion-canvas',\n",
       " 'https://github.com/TheAlgorithms/Python',\n",
       " 'https://github.com/waylaidwanderer/node-chatgpt-api',\n",
       " 'https://github.com/PowerJob/PowerJob',\n",
       " 'https://github.com/Zero6992/chatGPT-discord-bot',\n",
       " 'https://github.com/acikkaynak/deprem-yardim-projesi',\n",
       " 'https://github.com/zhayujie/chatgpt-on-wechat',\n",
       " 'https://github.com/TEXTurePaper/TEXTurePaper',\n",
       " 'https://github.com/PlexPt/awesome-chatgpt-prompts-zh',\n",
       " 'https://github.com/djun/wechatbot',\n",
       " 'https://github.com/A-poc/BlueTeam-Tools',\n",
       " 'https://github.com/devfullcycle/imersao12',\n",
       " 'https://github.com/acheong08/ChatGPT',\n",
       " 'https://github.com/LAION-AI/Open-Assistant',\n",
       " 'https://github.com/lencx/ChatGPT',\n",
       " 'https://github.com/eatmoreapple/openwechat',\n",
       " 'https://github.com/AIGCT/EASYChatGPT',\n",
       " 'https://github.com/imDazui/Tvlist-awesome-m3u-m3u8',\n",
       " 'https://github.com/wangrongding/wechat-bot']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL=[]    \n",
    "url=driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in url:\n",
    "    URL.append(i.get_attribute('href'))\n",
    "URL    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "703d7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/div/div[1]/div/div/span[1]/a')\n",
    "        Repository_title.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0593bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[1]/div/p')\n",
    "        Repository_description.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6613b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[5]/div/h2/a/span')\n",
    "        Contributors_count.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f961878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[6]/div/ul')\n",
    "        Language_used.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4398f70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acikkaynak</td>\n",
       "      <td>afetharita.com frontend projesi. https://rc.af...</td>\n",
       "      <td>71</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acikkaynak</td>\n",
       "      <td>afetharita.com backend projesi</td>\n",
       "      <td>-</td>\n",
       "      <td>Python\\n96.0%\\nDockerfile\\n2.4%\\nShell\\n1.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AutumnWhj</td>\n",
       "      <td>ChatGPT for wechat https://github.com/AutumnWh...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuergaosi233</td>\n",
       "      <td>Use ChatGPT On Wechat via wechaty</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dabit3</td>\n",
       "      <td>Create a travel itinerary for any city in the ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>This repo includes ChatGPT prompt curation to ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motion-canvas</td>\n",
       "      <td>Visualize Complex Ideas Programmatically</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheAlgorithms</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>waylaidwanderer</td>\n",
       "      <td>A ChatGPT implementation using the official Ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript\\n99.3%\\nDockerfile\\n0.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PowerJob</td>\n",
       "      <td>Enterprise job scheduling middleware with dist...</td>\n",
       "      <td>17</td>\n",
       "      <td>Java\\n98.8%\\nOther\\n1.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zero6992</td>\n",
       "      <td>Integrate ChatGPT into your own discord bot</td>\n",
       "      <td>11</td>\n",
       "      <td>Python\\n99.0%\\nDockerfile\\n1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acikkaynak</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zhayujie</td>\n",
       "      <td>使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wecha...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEXTurePaper</td>\n",
       "      <td>Official Implementation for \"TEXTure: Semantic...</td>\n",
       "      <td>3</td>\n",
       "      <td>Python\\n100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PlexPt</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>djun</td>\n",
       "      <td>为个人微信接入ChatGPT</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A-poc</td>\n",
       "      <td>Tools and Techniques for Blue Team / Incident ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>devfullcycle</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>acheong08</td>\n",
       "      <td>Reverse engineered ChatGPT API</td>\n",
       "      <td>55</td>\n",
       "      <td>Python\\n100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAION-AI</td>\n",
       "      <td>OpenAssistant is a chat-based assistant that u...</td>\n",
       "      <td>132</td>\n",
       "      <td>Python\\n68.1%\\nTypeScript\\n29.3%\\nJavaScript\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lencx</td>\n",
       "      <td>🔮 ChatGPT Desktop Application (Mac, Windows an...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>eatmoreapple</td>\n",
       "      <td>golang微信SDK</td>\n",
       "      <td>103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AIGCT</td>\n",
       "      <td>This is an application project of 'chatgpt',on...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>imDazui</td>\n",
       "      <td>直播源相关资源汇总 📺 💯 IPTV、M3U —— 勤洗手、戴口罩，祝愿所有人百毒不侵</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wangrongding</td>\n",
       "      <td>🤖一个基于OpenAi ChatGPT + WeChaty 实现的微信机器人 ，可以用来帮助...</td>\n",
       "      <td>6</td>\n",
       "      <td>JavaScript\\n85.0%\\nDockerfile\\n9.2%\\nShell\\n5.8%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Repository Title                             Repository Description  \\\n",
       "0        acikkaynak  afetharita.com frontend projesi. https://rc.af...   \n",
       "1        acikkaynak                     afetharita.com backend projesi   \n",
       "2         AutumnWhj  ChatGPT for wechat https://github.com/AutumnWh...   \n",
       "3      fuergaosi233                  Use ChatGPT On Wechat via wechaty   \n",
       "4            dabit3  Create a travel itinerary for any city in the ...   \n",
       "5                 f  This repo includes ChatGPT prompt curation to ...   \n",
       "6     motion-canvas           Visualize Complex Ideas Programmatically   \n",
       "7     TheAlgorithms               All Algorithms implemented in Python   \n",
       "8   waylaidwanderer  A ChatGPT implementation using the official Ch...   \n",
       "9          PowerJob  Enterprise job scheduling middleware with dist...   \n",
       "10         Zero6992        Integrate ChatGPT into your own discord bot   \n",
       "11       acikkaynak                                                  -   \n",
       "12         zhayujie  使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wecha...   \n",
       "13     TEXTurePaper  Official Implementation for \"TEXTure: Semantic...   \n",
       "14           PlexPt                ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。   \n",
       "15             djun                                     为个人微信接入ChatGPT   \n",
       "16            A-poc  Tools and Techniques for Blue Team / Incident ...   \n",
       "17     devfullcycle                                                  -   \n",
       "18        acheong08                     Reverse engineered ChatGPT API   \n",
       "19         LAION-AI  OpenAssistant is a chat-based assistant that u...   \n",
       "20            lencx  🔮 ChatGPT Desktop Application (Mac, Windows an...   \n",
       "21     eatmoreapple                                        golang微信SDK   \n",
       "22            AIGCT  This is an application project of 'chatgpt',on...   \n",
       "23          imDazui        直播源相关资源汇总 📺 💯 IPTV、M3U —— 勤洗手、戴口罩，祝愿所有人百毒不侵   \n",
       "24     wangrongding  🤖一个基于OpenAi ChatGPT + WeChaty 实现的微信机器人 ，可以用来帮助...   \n",
       "\n",
       "   Contributors Count                                      Language Used  \n",
       "0                  71                                                  -  \n",
       "1                   -       Python\\n96.0%\\nDockerfile\\n2.4%\\nShell\\n1.6%  \n",
       "2                   -                                                  -  \n",
       "3                   -                                                  -  \n",
       "4                   -                                                  -  \n",
       "5                   -                                                  -  \n",
       "6                   -                                                  -  \n",
       "7                   2                                                     \n",
       "8                   5                JavaScript\\n99.3%\\nDockerfile\\n0.7%  \n",
       "9                  17                           Java\\n98.8%\\nOther\\n1.2%  \n",
       "10                 11                    Python\\n99.0%\\nDockerfile\\n1.0%  \n",
       "11                  5                                                  -  \n",
       "12                  -                                                  -  \n",
       "13                  3                                     Python\\n100.0%  \n",
       "14                  -                                                  -  \n",
       "15                  -                                                  -  \n",
       "16                  -                                                  -  \n",
       "17                  -                                                  -  \n",
       "18                 55                                     Python\\n100.0%  \n",
       "19                132  Python\\n68.1%\\nTypeScript\\n29.3%\\nJavaScript\\n...  \n",
       "20                  -                                                  -  \n",
       "21                103                                                     \n",
       "22                  -                                                  -  \n",
       "23                  -                                                  -  \n",
       "24                  6   JavaScript\\n85.0%\\nDockerfile\\n9.2%\\nShell\\n5.8%  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Repository Title':Repository_title,'Repository Description':Repository_description,'Contributors Count':Contributors_count,'Language Used':Language_used})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e748cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\rudra\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c1a3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button')\n",
    "source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5feb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button')\n",
    "Source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca541408",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source1=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "Source1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d799c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87b5e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text.split('\\n')[0]\n",
    "    Song_name.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b1fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text.split('\\n')[1]\n",
    "    Artist_name.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8efa37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text.split('\\n')[2]\n",
    "    Last_week_rank.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e61c728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text.split('\\n')[3]\n",
    "    Peak_rank.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e879970",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text.split('\\n')[4]\n",
    "    Weeks_on_board.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "025a110a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Week on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hey Mor</td>\n",
       "      <td>Ozuna Featuring Feid</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Gato de Noche</td>\n",
       "      <td>Nengo Flow &amp; Bad Bunny</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heart To Heart</td>\n",
       "      <td>Mac DeMarco</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Never Gonna Not Dance Again</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dancin' In The Country</td>\n",
       "      <td>Tyler Hubbard</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song Name                           Artist Name  \\\n",
       "0                       Flowers                           Miley Cyrus   \n",
       "1                     Kill Bill                                   SZA   \n",
       "2                      Creepin'  Metro Boomin, The Weeknd & 21 Savage   \n",
       "3                     Anti-Hero                          Taylor Swift   \n",
       "4                        Unholy                Sam Smith & Kim Petras   \n",
       "..                          ...                                   ...   \n",
       "95                      Hey Mor                  Ozuna Featuring Feid   \n",
       "96                Gato de Noche                Nengo Flow & Bad Bunny   \n",
       "97               Heart To Heart                           Mac DeMarco   \n",
       "98  Never Gonna Not Dance Again                                  P!nk   \n",
       "99       Dancin' In The Country                         Tyler Hubbard   \n",
       "\n",
       "   Last Week Rank Peak Rank Week on board  \n",
       "0               1         1             3  \n",
       "1               2         2             8  \n",
       "2               4         3             9  \n",
       "3               3         1            15  \n",
       "4               5         1            19  \n",
       "..            ...       ...           ...  \n",
       "95              -        96             1  \n",
       "96             85        60             6  \n",
       "97             83        83             3  \n",
       "98              -        99             1  \n",
       "99              -       100             1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Song Name':Song_name,'Artist Name':Artist_name,'Last Week Rank':Last_week_rank,'Peak Rank':Peak_rank,'Week on board':Weeks_on_board})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "157c7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\rudra\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d995a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e86892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')[1:500:5]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Book_name.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ff600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')[2:500:5]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Author_name.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b99128be",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')[3:500:5]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Volumes_sold.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc64e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')[4:500:5]\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Publisher.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e437a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre1=[]\n",
    "brand=driver.find_elements(By.XPATH,'//td[@class=\"last left\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Genre1.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feecb228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Book Name':Book_name,'Author Name':Author_name,'Volumes Sold':Volumes_sold,'Publisher':Publisher,'Genre':Genre1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11fb83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\rudra\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4372ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f65f6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text[2:]\n",
    "    Name.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5db7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Year_span.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "801227fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Genre.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b23cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Run_time.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66ed74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Ratings.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5e809eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Votes.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bff146e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones (2011–2019)</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,120,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things (2016–2024)</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,209,311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead (2010–2022)</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,005,722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why (2017–2020)</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>296,825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100 (2014–2020)</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>255,776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>. Reign (2013–2017)</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>. A Series of Unfortunate Events (2017–2019)</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>62,574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>. Criminal Minds (2005– )</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>202,583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>. Scream: The TV Series (2015–2019)</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>250,408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name    Year Span  \\\n",
       "0                    Game of Thrones (2011–2019)  (2011–2019)   \n",
       "1                    Stranger Things (2016–2024)  (2016–2024)   \n",
       "2                   The Walking Dead (2010–2022)  (2010–2022)   \n",
       "3                     13 Reasons Why (2017–2020)  (2017–2020)   \n",
       "4                            The 100 (2014–2020)  (2014–2020)   \n",
       "..                                           ...          ...   \n",
       "95                           . Reign (2013–2017)  (2013–2017)   \n",
       "96  . A Series of Unfortunate Events (2017–2019)  (2017–2019)   \n",
       "97                     . Criminal Minds (2005– )     (2005– )   \n",
       "98           . Scream: The TV Series (2015–2019)  (2015–2019)   \n",
       "99          0. The Haunting of Hill House (2018)       (2018)   \n",
       "\n",
       "                       Genre Run time Ratings      Votes  \n",
       "0   Action, Adventure, Drama   57 min     9.2  2,120,851  \n",
       "1     Drama, Fantasy, Horror   51 min     8.7  1,209,311  \n",
       "2    Drama, Horror, Thriller   44 min     8.1  1,005,722  \n",
       "3   Drama, Mystery, Thriller   60 min     7.5    296,825  \n",
       "4     Drama, Mystery, Sci-Fi   43 min     7.6    255,776  \n",
       "..                       ...      ...     ...        ...  \n",
       "95                     Drama   42 min     7.4     50,694  \n",
       "96  Adventure, Comedy, Drama   50 min     7.8     62,574  \n",
       "97     Crime, Drama, Mystery   42 min     8.1    202,583  \n",
       "98      Comedy, Crime, Drama   45 min     7.1     42,018  \n",
       "99    Drama, Horror, Mystery  572 min     8.6    250,408  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':Name,'Year Span':Year_span,'Genre':Genre,'Run time':Run_time,'Ratings':Ratings,'Votes':Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed456bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\rudra\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c42a9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a')\n",
    "source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "114ad568",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb3b0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Dataset_name.append(brand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1845883e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Adult',\n",
       " 'Annealing',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " 'Arrhythmia',\n",
       " 'Artificial Characters',\n",
       " 'Audiology (Original)',\n",
       " 'Audiology (Standardized)',\n",
       " 'Auto MPG',\n",
       " 'Automobile',\n",
       " 'Badges',\n",
       " 'Balance Scale',\n",
       " 'Balloons',\n",
       " 'Breast Cancer',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Car Evaluation',\n",
       " 'Census Income',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Bach Chorales',\n",
       " 'Connect-4',\n",
       " 'Credit Approval',\n",
       " 'Japanese Credit Screening',\n",
       " 'Computer Hardware',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Covertype',\n",
       " 'Cylinder Bands',\n",
       " 'Dermatology',\n",
       " 'Diabetes',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Document Understanding',\n",
       " 'EBL Domain Theories',\n",
       " 'Echocardiogram',\n",
       " 'Ecoli',\n",
       " 'Flags',\n",
       " 'Function Finding',\n",
       " 'Glass Identification',\n",
       " \"Haberman's Survival\",\n",
       " 'Hayes-Roth',\n",
       " 'Heart Disease',\n",
       " 'Hepatitis',\n",
       " 'Horse Colic',\n",
       " 'ICU',\n",
       " 'Image Segmentation',\n",
       " 'Internet Advertisements',\n",
       " 'Ionosphere',\n",
       " 'Iris',\n",
       " 'ISOLET',\n",
       " 'Kinship',\n",
       " 'Labor Relations',\n",
       " 'LED Display Domain',\n",
       " 'Lenses',\n",
       " 'Letter Recognition',\n",
       " 'Liver Disorders',\n",
       " 'Logic Theorist',\n",
       " 'Lung Cancer',\n",
       " 'Lymphography',\n",
       " 'Mechanical Analysis',\n",
       " 'Meta-data',\n",
       " 'Mobile Robots',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"MONK's Problems\",\n",
       " 'Moral Reasoner',\n",
       " 'Multiple Features',\n",
       " 'Mushroom',\n",
       " 'Musk (Version 1)',\n",
       " 'Musk (Version 2)',\n",
       " 'Nursery',\n",
       " 'Othello Domain Theory',\n",
       " 'Page Blocks Classification',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Post-Operative Patient',\n",
       " 'Primary Tumor',\n",
       " 'Prodigy',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Quadruped Mammals',\n",
       " 'Servo',\n",
       " 'Shuttle Landing Control',\n",
       " 'Solar Flare',\n",
       " 'Soybean (Large)',\n",
       " 'Soybean (Small)',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Spambase',\n",
       " 'SPECT Heart',\n",
       " 'SPECTF Heart',\n",
       " 'Sponge',\n",
       " 'Statlog Project',\n",
       " 'Student Loan Relational',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Thyroid Disease',\n",
       " 'Trains',\n",
       " 'University',\n",
       " 'Congressional Voting Records',\n",
       " 'Water Treatment Plant',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Wine',\n",
       " 'Yeast',\n",
       " 'Zoo',\n",
       " 'Undocumented',\n",
       " 'Twenty Newsgroups',\n",
       " 'Australian Sign Language signs',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'US Census Data (1990)',\n",
       " 'Census-Income (KDD)',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Corel Image Features',\n",
       " 'E. Coli Genes',\n",
       " 'EEG Database',\n",
       " 'El Nino',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'CMU Face Images',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Internet Usage Data',\n",
       " 'IPUMS Census Database',\n",
       " 'Japanese Vowels',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Movie',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Robot Execution Failures',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'UNIX User Data',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Statlog (Heart)',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " 'Economic Sanctions',\n",
       " 'Protein Data',\n",
       " 'Cloud',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Poker Hand',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'UJI Pen Characters',\n",
       " 'Mammographic Mass',\n",
       " 'Forest Fires',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Bag of Words',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Hill-Valley',\n",
       " 'Arcene',\n",
       " 'Dexter',\n",
       " 'Dorothea',\n",
       " 'Gisette',\n",
       " 'Madelon',\n",
       " 'Ozone Level Detection',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Parkinsons',\n",
       " 'Character Trajectories',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'SECOM',\n",
       " 'Plants',\n",
       " 'Libras Movement',\n",
       " 'Concrete Slump Test',\n",
       " 'Communities and Crime',\n",
       " 'Acute Inflammations',\n",
       " 'Wine Quality',\n",
       " 'URL Reputation',\n",
       " 'p53 Mutants',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Demospongiae',\n",
       " 'Opinosis Opinion ⁄ Review',\n",
       " 'Breast Tissue',\n",
       " 'Cardiotocography',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Localization Data for Person Activity',\n",
       " 'AutoUniv',\n",
       " 'Steel Plates Faults',\n",
       " 'MiniBooNE particle identification',\n",
       " 'YearPredictionMSD',\n",
       " 'PEMS-SF',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Vertebral Column',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Amazon Access Samples',\n",
       " 'Reuter_50_50',\n",
       " 'Farm Ads',\n",
       " 'DBWorld e-mails',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Bank Marketing',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Nomao',\n",
       " 'SMS Spam Collection',\n",
       " 'Skin Segmentation',\n",
       " 'Planning Relax',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Restaurant & consumer data',\n",
       " 'CNAE-9',\n",
       " 'Individual household electric power consumption',\n",
       " 'seeds',\n",
       " 'Northix',\n",
       " 'QtyT40I10D100K',\n",
       " 'Legal Case Reports',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'One-hundred plant species leaves data set',\n",
       " 'Energy efficiency',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Fertility',\n",
       " 'Daphnet Freezing of Gait',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Buzz in social media',\n",
       " 'First-order theorem proving',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'MicroMass',\n",
       " 'QSAR biodegradation',\n",
       " 'BLOGGER',\n",
       " 'Daily and Sports Activities',\n",
       " 'User Knowledge Modeling',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'NYSK',\n",
       " 'Turkiye Student Evaluation',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'EEG Eye State',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'seismic-bumps',\n",
       " 'banknote authentication',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'SML2010',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Thoracic Surgery Data',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'SUSY',\n",
       " 'HIGGS',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Wilt',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Leaf',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Wholesale customers',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Urban Land Cover',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Bach Choral Harmony',\n",
       " 'StoneFlakes',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Perfume Data',\n",
       " 'BlogFeedback',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'UJIIndoorLoc',\n",
       " 'Sentence Classification',\n",
       " 'Dow Jones Index',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Geographical Original of Music',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'NoisyOffice',\n",
       " 'MHEALTH Dataset',\n",
       " 'Student Performance',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'microblogPCU',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Phishing Websites',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Online News Popularity',\n",
       " 'Forest type mapping',\n",
       " 'wiki4HE',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Folio',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Mice Protein Expression',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'HEPMASS',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'default of credit card clients',\n",
       " 'Mesothelioma’s disease data set',\n",
       " 'Online Retail',\n",
       " 'SIFT10M',\n",
       " 'GPS Trajectories',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Occupancy Detection',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       " 'News Aggregator',\n",
       " 'Air Quality',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Dota2 Games Results',\n",
       " 'Facebook metrics',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'HTRU2',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Appliances energy prediction',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'DrivFace',\n",
       " 'Website Phishing',\n",
       " 'YouTube Spam Collection',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'KASANDR',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Air quality',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " 'Stock portfolio performance',\n",
       " 'MoCap Hand Postures',\n",
       " 'Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Las Vegas Strip',\n",
       " 'Eco-hotel',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Crowdsourced Mapping',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'chestnut – LARVIC',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Paper Reviews',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " 'Z-Alizadeh Sani',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'IDA2016Challenge',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Character Font Images',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Wireless Indoor Localization',\n",
       " 'HCC Survival',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Autism Screening Adult',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Cryotherapy Dataset',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Residential Building Data Set',\n",
       " 'Health News in Twitter',\n",
       " 'chipseq',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Absenteeism at work',\n",
       " 'SCADI',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Carbon Nanotubes',\n",
       " 'Optical Interconnection Network',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Avila',\n",
       " 'PANDOR',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Superconductivty Data',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Student Academics Performance',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'PMU-UD',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'BAUM-1',\n",
       " 'BAUM-2',\n",
       " 'Audit Data',\n",
       " 'BuddyMove Data Set',\n",
       " 'Real estate valuation data set',\n",
       " 'Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       " 'Somerville Happiness Survey',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'EMG data for gestures',\n",
       " 'Parking Birmingham',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Travel Reviews',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Wave Energy Converters',\n",
       " 'PPG-DaLiA',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " 'Incident management process enriched event log',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'MEx',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Online Retail II',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'QSAR fish toxicity',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'QSAR oral toxicity',\n",
       " 'QSAR androgen receptor',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Heart failure clinical records',\n",
       " 'Deepfakes: Medical Image Tamper Detection',\n",
       " 'selfBACK',\n",
       " 'South German Credit',\n",
       " 'Exasens',\n",
       " 'Swarm Behaviour',\n",
       " 'Crop mapping using fused optical-radar data set',\n",
       " 'BitcoinHeistRansomwareAddressDataset',\n",
       " 'Facebook Large Page-Page Network',\n",
       " 'Amphibians',\n",
       " 'Early stage diabetes risk prediction dataset.',\n",
       " 'Turkish Spam V01',\n",
       " 'Stock keeping units',\n",
       " 'Demand Forecasting for a store',\n",
       " 'Detect Malware Types',\n",
       " 'Wave Energy Converters',\n",
       " 'Youtube cookery channels viewers comments in Hinglish',\n",
       " 'Pedestrian in Traffic Dataset',\n",
       " 'Cervical Cancer Behavior Risk',\n",
       " 'Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " '3W dataset',\n",
       " 'Malware static and dynamic features VxHeaven and Virus Total',\n",
       " 'Internet Firewall Data',\n",
       " 'User Profiling and Abusive Language Detection Dataset',\n",
       " 'Estimation of obesity levels based on eating habits and physical condition',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Vehicle routing and scheduling problems',\n",
       " 'Algerian Forest Fires Dataset',\n",
       " 'Breath Metabolomics',\n",
       " 'Horton General Hospital',\n",
       " 'UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " 'Gas Turbine CO and NOx Emission Data Set',\n",
       " 'Activity recognition using wearable physiological measurements',\n",
       " 'clickstream data for online shopping',\n",
       " 'CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " 'Apartment for rent classified',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Nasarian CAD Dataset',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Seoul Bike Sharing Demand',\n",
       " 'Person Classification Gait Data',\n",
       " 'Shill Bidding Dataset',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Bone marrow transplant: children',\n",
       " 'Exasens',\n",
       " 'COVID-19 Surveillance',\n",
       " 'Refractive errors',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'CLINC150',\n",
       " 'HCV data',\n",
       " 'Taiwanese Bankruptcy Prediction',\n",
       " 'South German Credit (UPDATE)',\n",
       " 'IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " 'Guitar Chords finger positions',\n",
       " 'Russian Corpus of Biographical Texts',\n",
       " 'Codon usage',\n",
       " 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " 'Myocardial infarction complications',\n",
       " 'Hungarian Chickenpox Cases',\n",
       " 'Simulated data for survival modelling',\n",
       " 'Student Performance on an entrance examination',\n",
       " 'Chemical Composition of Ceramic Samples',\n",
       " 'Labeled Text Forum Threads Dataset',\n",
       " 'Stock keeping units',\n",
       " 'BLE RSSI dataset for Indoor localization',\n",
       " 'Basketball dataset',\n",
       " 'GitHub MUSAE',\n",
       " 'Anticancer peptides',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Gender by Name',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wheat kernels',\n",
       " 'Productivity Prediction of Garment Employees',\n",
       " 'Multi-view Brain Networks',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wisesight Sentiment Corpus',\n",
       " 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'Dry Bean Dataset',\n",
       " 'in-vehicle coupon recommendation',\n",
       " 'Gait Classification',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Synchronous Machine Data Set',\n",
       " 'Average Localization Error (ALE) in sensor node localization process in WSNs',\n",
       " '9mers from cullpdb',\n",
       " 'TamilSentiMix',\n",
       " 'Accelerometer',\n",
       " 'Synchronous Machine Data Set',\n",
       " 'Pedal Me Bicycle Deliveries',\n",
       " 'Turkish Headlines Dataset',\n",
       " 'Secondary Mushroom Dataset',\n",
       " 'Power consumption of Tetouan city',\n",
       " 'Raisin Dataset',\n",
       " 'Steel Industry Energy Consumption Dataset',\n",
       " 'Gender Gap in Spanish WP',\n",
       " 'Non verbal tourists data',\n",
       " 'Roman Urdu Sentiment Analysis Dataset (RUSAD)',\n",
       " 'TUANDROMD ( Tezpur University Android Malware Dataset)',\n",
       " 'Higher Education Students Performance Evaluation Dataset',\n",
       " 'Risk Factor prediction of Chronic Kidney Disease',\n",
       " 'Lab Test',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'Rocket League Skillshots Data Set',\n",
       " 'Sepsis survival minimal clinical records',\n",
       " 'Water Quality Prediction',\n",
       " 'Traffic Flow Forecasting',\n",
       " 'sentiment analysis in Saudi Arabia about distance education during Covid-19',\n",
       " 'Kain Tradisional Sambas',\n",
       " 'Image Recognition Task Execution Times in Mobile Edge Computing',\n",
       " 'REWEMA',\n",
       " 'REJAFADA',\n",
       " 'Steel Industry Energy Consumption Dataset',\n",
       " 'Influenza outbreak event prediction via Twitter data',\n",
       " 'Turkish Music Emotion Dataset',\n",
       " 'Maternal Health Risk Data Set',\n",
       " 'Room Occupancy Estimation',\n",
       " 'Image Recognition Task Execution Times in Mobile Edge Computing']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51d75a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Multivariate ']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[2]/td[2]/p\")\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Data_type.append(brand1)\n",
    "Data_type    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82b02e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification ']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[2]/td[3]/p\")\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Attribute_type.append(brand1)\n",
    "Attribute_type    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62c01f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification ']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[3]/td[3]/p\")\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Task.append(brand1)\n",
    "Task    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "645e2707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4177 ']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[2]/td[5]/p\")\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    No_of_instances.append(brand1)\n",
    "No_of_instances    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19ebf215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8 ']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[2]/td[6]/p\")\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    No_of_attribute.append(brand1)\n",
    "No_of_attribute    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef13f5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1995 ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[2]/td[7]/p\")\n",
    "for i in brand:\n",
    "    brand1=i.text\n",
    "    Year.append(brand1)\n",
    "Year    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb7e8964",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDataset Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mDataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mData_type\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAttribute type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mAttribute_type\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mTask\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo of instances\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mNo_of_instances\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo of attribute\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mNo_of_attribute\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mYear\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Dataset Name':Dataset_name,'Data Type':Data_type,'Attribute type':Attribute_type,'Task':Task,'No of instances':No_of_instances,'No of attribute':No_of_attribute,'Year':Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de741dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
